{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习的一个魅力在于神经网络中各式各样的层，例如全链接层和后面章节中将要介绍的卷积层、池化层与循环层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 不含模型参数的自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的CenteredLayer类通过继承Block类自定义了一个将输入减掉均值后输出的层，并将层的计算定义在了forward函数里。这个层里不含模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class CenteredLayer(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x - x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-2. -1.  0.  1.  2.]\n",
       "<NDArray 5 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(nd.array([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(128),\n",
    "        CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.421477e-10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "y = net(nd.random_uniform(shape=(4, 8)))\n",
    "y.mean().asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 含模型参数的自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在自定义含模型参数的层时，我们可以利用Block类自带的ParameterDict类型的成员变量params。它是一个由字符串类型的参数名字映射到Prameter类型的模型参数的字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  Parameter param2 (shape=(2, 3), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = gluon.ParameterDict()\n",
    "params.get('param2', shape=(2, 3))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Block):\n",
    "    # units为该层的输出个数，in_units为该层的输入个数\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=(in_units, units))\n",
    "        self.bias = self.params.get('bias', shape=(units,))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = nd.dot(x, self.weight.data()) + self.bias.data()\n",
    "        return nd.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化MyDense类并访问它的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mydense0_ (\n",
       "  Parameter mydense0_weight (shape=(5, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter mydense0_bias (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = MyDense(units=3, in_units=5)\n",
    "dense.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接使用自定义层做前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.         0.04648931 0.09400678]\n",
       " [0.         0.         0.02732784]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.initialize()\n",
    "dense(nd.random_uniform(shape=(2, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义层构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.]\n",
       " [0.]]\n",
       "<NDArray 2x1 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(MyDense(units=8, in_units=64),\n",
    "        MyDense(units=1, in_units=8))\n",
    "net.initialize()\n",
    "net(nd.random_uniform(shape=(2, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以通过Block类自定义神经网络中的层，从而可以被重复调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义一个层，使用它做一次前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个层\n",
    "class MyFavouriteDense(nn.Block):\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=(in_units, units))\n",
    "        self.bias = self.params.get('bias', shape=(units,))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = nd.dot(x, self.weight.data()) + self.bias.data()\n",
    "        return nd.sigmoid(linear)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myfavouritedense0_ (\n",
       "  Parameter myfavouritedense0_weight (shape=(12, 9), dtype=<class 'numpy.float32'>)\n",
       "  Parameter myfavouritedense0_bias (shape=(9,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化MyFavouriteDense类并访问它的模型参数\n",
    "dense = MyFavouriteDense(units=9, in_units=12)\n",
    "dense.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.49905163 0.49295434 0.5168587  0.4825667  0.5245432  0.4909766\n",
       "  0.5034553  0.48245028 0.45977002]\n",
       " [0.49888033 0.49145684 0.52476823 0.49484724 0.53001577 0.4946552\n",
       "  0.50558215 0.4857613  0.45687237]\n",
       " [0.5083423  0.46598774 0.5103539  0.4894063  0.544457   0.4700225\n",
       "  0.53259134 0.5102469  0.49325272]\n",
       " [0.4959993  0.49639025 0.5172226  0.4860539  0.52686733 0.48333624\n",
       "  0.50136    0.49174598 0.4742024 ]\n",
       " [0.501645   0.4874378  0.5178983  0.48653585 0.547457   0.48724288\n",
       "  0.5272622  0.5117731  0.4895995 ]\n",
       " [0.51400006 0.46848547 0.5123003  0.49393123 0.56081426 0.47711363\n",
       "  0.5343128  0.4905582  0.4746947 ]\n",
       " [0.52215135 0.46523327 0.51617795 0.5023349  0.5504886  0.47045365\n",
       "  0.5270774  0.5174171  0.48272058]\n",
       " [0.51155794 0.49104097 0.5438664  0.51329374 0.54477245 0.49041986\n",
       "  0.51305145 0.5159679  0.4611001 ]\n",
       " [0.50187725 0.49816912 0.509491   0.49487978 0.5290062  0.47594476\n",
       "  0.5120902  0.51532465 0.47845086]\n",
       " [0.50262594 0.491421   0.5157757  0.48444003 0.5297511  0.49628147\n",
       "  0.51272345 0.5032552  0.49312043]\n",
       " [0.50241774 0.476192   0.5302534  0.5062667  0.5545545  0.47418368\n",
       "  0.52610147 0.5199682  0.48018527]\n",
       " [0.5081994  0.50129884 0.527238   0.4867267  0.5326019  0.4911294\n",
       "  0.49332798 0.50017273 0.46340156]\n",
       " [0.4923699  0.48154685 0.5115194  0.48968965 0.55413204 0.45963213\n",
       "  0.5231618  0.5064839  0.48192143]\n",
       " [0.5096844  0.4754038  0.5263832  0.49466202 0.55302125 0.47118774\n",
       "  0.5058051  0.51478255 0.47223714]\n",
       " [0.5067595  0.48774618 0.50943726 0.4842147  0.55295324 0.47209617\n",
       "  0.5089718  0.51632077 0.49633387]\n",
       " [0.51743925 0.47699067 0.5295676  0.5039964  0.54250747 0.48131943\n",
       "  0.5096484  0.5096666  0.47240335]\n",
       " [0.51477146 0.49161646 0.53064406 0.4942199  0.5420222  0.49353358\n",
       "  0.5175183  0.51898557 0.47659165]\n",
       " [0.5095966  0.48944765 0.50885236 0.48119152 0.5514372  0.4745972\n",
       "  0.5065296  0.5225622  0.4957505 ]\n",
       " [0.5036586  0.48938322 0.5398268  0.5142596  0.51219743 0.48913983\n",
       "  0.5163126  0.51754725 0.47933665]\n",
       " [0.4918323  0.49783564 0.5206814  0.49087638 0.5249933  0.4739115\n",
       "  0.49475187 0.50817597 0.46470523]\n",
       " [0.51828945 0.48071912 0.52413076 0.50406086 0.5424815  0.48729903\n",
       "  0.51763886 0.5083932  0.47161084]\n",
       " [0.49497098 0.47380108 0.5201528  0.47518456 0.5235963  0.47949195\n",
       "  0.5142974  0.49034175 0.47784036]\n",
       " [0.5177445  0.5031619  0.5411106  0.51572424 0.5342393  0.49527258\n",
       "  0.50392824 0.5220945  0.47813243]\n",
       " [0.500704   0.48704296 0.53063095 0.48642877 0.55158395 0.48702917\n",
       "  0.5079817  0.52856195 0.47438422]\n",
       " [0.49756172 0.5054607  0.5218735  0.49358964 0.5263218  0.4924921\n",
       "  0.5131349  0.50657177 0.47162467]\n",
       " [0.5093073  0.48643926 0.5229087  0.49709776 0.54498494 0.4776054\n",
       "  0.5146084  0.48209465 0.46925253]\n",
       " [0.5068426  0.48457825 0.525143   0.5157651  0.5372039  0.48054424\n",
       "  0.5277244  0.5029034  0.46242592]\n",
       " [0.50923437 0.49506325 0.5332869  0.5070513  0.54117066 0.48676324\n",
       "  0.512829   0.5295893  0.47727758]\n",
       " [0.49787256 0.49973342 0.52665454 0.49193907 0.53963697 0.48558712\n",
       "  0.51571125 0.49043253 0.45255527]\n",
       " [0.50215226 0.4987921  0.51156294 0.48848578 0.53840303 0.48108247\n",
       "  0.5213185  0.5171562  0.48405325]\n",
       " [0.51372045 0.49615806 0.5186627  0.49693814 0.5529039  0.47708455\n",
       "  0.5076284  0.4986581  0.47153768]\n",
       " [0.4970538  0.49642116 0.5173043  0.4896765  0.54326886 0.48199797\n",
       "  0.49686974 0.49780276 0.45647037]\n",
       " [0.4998652  0.48279402 0.5298231  0.5021501  0.5337336  0.4784457\n",
       "  0.5241313  0.49086925 0.47231442]\n",
       " [0.5056241  0.48466882 0.5171014  0.4871629  0.55702496 0.4823119\n",
       "  0.5244317  0.5079239  0.49354288]\n",
       " [0.5090225  0.48518276 0.5274626  0.509471   0.53955674 0.48589906\n",
       "  0.52665174 0.51469064 0.49264815]\n",
       " [0.5092843  0.48550096 0.5176619  0.4915906  0.55772865 0.47682604\n",
       "  0.50926375 0.52088875 0.48537776]\n",
       " [0.50872374 0.4841078  0.51627815 0.48550603 0.5674089  0.4753124\n",
       "  0.51515657 0.49576873 0.46468526]\n",
       " [0.5010231  0.48524877 0.51329595 0.49004123 0.546251   0.46997726\n",
       "  0.50834304 0.49130613 0.47056937]\n",
       " [0.50318    0.50811875 0.5224475  0.4953676  0.5491904  0.4741875\n",
       "  0.49233404 0.5278788  0.48657626]\n",
       " [0.50017464 0.4794219  0.5346079  0.5108676  0.53569555 0.48699468\n",
       "  0.5301876  0.5076234  0.48062426]\n",
       " [0.51334417 0.50205064 0.52802336 0.50609773 0.52793276 0.49044463\n",
       "  0.50702477 0.505897   0.45988396]\n",
       " [0.5110678  0.4801039  0.51435083 0.48795578 0.56556743 0.47944328\n",
       "  0.516064   0.51243603 0.49345833]\n",
       " [0.5054136  0.50441074 0.5182872  0.48786595 0.52616864 0.491736\n",
       "  0.5108451  0.51581824 0.47610143]\n",
       " [0.50003046 0.48511901 0.5213097  0.50324523 0.541879   0.46775866\n",
       "  0.51468253 0.51558685 0.48618627]\n",
       " [0.5063724  0.4902308  0.531889   0.49370983 0.5409742  0.47978857\n",
       "  0.5043841  0.512314   0.46397054]\n",
       " [0.5049997  0.49356768 0.53371555 0.5060548  0.55043554 0.4820823\n",
       "  0.5125158  0.5177201  0.47106126]\n",
       " [0.4987715  0.4942983  0.51928484 0.49568188 0.5211918  0.47860858\n",
       "  0.5006792  0.49792004 0.47005463]\n",
       " [0.51694447 0.49592787 0.5227507  0.5181606  0.5472311  0.47545174\n",
       "  0.5248766  0.507928   0.46557865]\n",
       " [0.51456106 0.48643023 0.51283115 0.4887962  0.53526103 0.48091587\n",
       "  0.50612426 0.5056295  0.49604422]\n",
       " [0.50492144 0.4795233  0.5179549  0.4873498  0.5416997  0.47652322\n",
       "  0.51021266 0.4910682  0.4931331 ]]\n",
       "<NDArray 50x9 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用自定义层做前向计算\n",
    "dense.initialize()\n",
    "dense(nd.random_uniform(shape=(50, 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
