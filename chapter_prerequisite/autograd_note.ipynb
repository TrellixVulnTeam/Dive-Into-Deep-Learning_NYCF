{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 自动求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，我们经常需要对函数求梯度(gradient)。本节将介绍如何使用MXNet提供的autograd模块来自动求梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 简单例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先看一个简单例子：对函数 $y = 2\\boldsymbol{x}^{\\top}\\boldsymbol{x}$ 求关于列向量 $\\boldsymbol{x}$ 的梯度。我们先创建变量`x`，并赋初值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.]\n",
       " [1.]\n",
       " [2.]\n",
       " [3.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.arange(4).reshape(4, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了求有关变量x的梯度，我们需要先调用attach_grad函数来申请存储梯度所需要的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面定义有关变量x的函数。为了减少计算和内存开销，默认条件下MXNet不会记录用于求梯度的计算。我们需要调用record函数来要求MXNet记录与求梯度有关的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autograd.record():\n",
    "    y = 2 * nd.dot(x.T, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于x的形状为(4, 1)，y是一个标量。接下来我们可以通过调用backward函数自动求梯度。需要注意的是，如果y不是一个标量，MXNet将默认先对y中元素求和得到新的变量，再求该变量有关x的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数 $y = 2\\boldsymbol{x}^{\\top}\\boldsymbol{x}$ 关于$\\boldsymbol{x}$ 的梯度应为$4\\boldsymbol{x}$。现在我们来验证一下求出来的梯度是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.]\n",
       " [ 4.]\n",
       " [ 8.]\n",
       " [12.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (x.grad - 4 * x).norm().asscalar() == 0\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 训练模式和预测模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面可以看出，在调用record函数后，MXNet会记录并计算梯度。此外，默认情况下autograd还会将运行模式从预测模式转为训练模式。这可以通过调用is_training函数来查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(autograd.is_training())\n",
    "with autograd.record():\n",
    "    print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在有些情况下，同一个模型在训练模式和预测模式下的行为并不相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 对Python控制流求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用MXNet的一个便利之处是，即使函数的计算图包含了Python的控制流(如条件和循环控制)，我们也有可能对变量求梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑下面的程序，其中包含Python的条件和循环控制。需要强调的是，这里循环(while循环)迭代的次数和条件判断(if语句)的执行都取决于输入a的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm().asscalar() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum().asscalar() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们像之前一样使用record函数记录计算，并调用backward函数来求梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nd.random.normal(shape=1)\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c = f(a)\n",
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1024.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert a.grad == c / a\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习参考答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)在本节对控制流求梯度的例子中，把变量a改成一个随机向量或矩阵。此时计算结果c不再是标量，运行结果将有何变化？该如何分析该结果？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------把变量a改成3行4列的矩阵--------\n",
      "\n",
      "[[ 0.5712682  -2.7579627   1.07628    -0.6141326 ]\n",
      " [ 1.8307649  -1.1468065   0.05383795 -2.5074806 ]\n",
      " [-0.59164983  0.8586049  -0.22794184  0.20131476]]\n",
      "<NDArray 3x4 @cpu(0)>\n",
      "\n",
      "[[25600. 25600. 25600. 25600.]\n",
      " [25600. 25600. 25600. 25600.]\n",
      " [25600. 25600. 25600. 25600.]]\n",
      "<NDArray 3x4 @cpu(0)>\n",
      "\n",
      "[[ 14624.466  -70603.84    27552.768  -15721.794 ]\n",
      " [ 46867.582  -29358.246    1378.2517 -64191.504 ]\n",
      " [-15146.235   21980.285   -5835.311    5153.6577]]\n",
      "<NDArray 3x4 @cpu(0)>\n",
      "\n",
      "------把变量a改成3行1列的列向量-------\n",
      "\n",
      "[[0.35005474]\n",
      " [0.5360521 ]\n",
      " [1.5194443 ]]\n",
      "<NDArray 3x1 @cpu(0)>\n",
      "\n",
      "[[1024.]\n",
      " [1024.]\n",
      " [1024.]]\n",
      "<NDArray 3x1 @cpu(0)>\n",
      "\n",
      "[[ 358.45605]\n",
      " [ 548.91736]\n",
      " [1555.911  ]]\n",
      "<NDArray 3x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"-------把变量a改成3行4列的矩阵--------\"\"\")\n",
    "a = nd.random.normal(shape=(3, 4))\n",
    "print(a)\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c = f(a)\n",
    "c.backward()\n",
    "\n",
    "print(a.grad)\n",
    "print(c)\n",
    "\n",
    "print(\"\"\"\\n------把变量a改成3行1列的列向量-------\"\"\")\n",
    "a = nd.random.normal(shape=3).reshape(3, 1)\n",
    "print(a)\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c = f(a)\n",
    "c.backward()\n",
    "\n",
    "print(a.grad)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面可以发现，把变量a改为一个随机的向量或矩阵时，计算结果c也为一个向量或矩阵，得到关于a的梯度也为向量或矩阵。运算结果的判断方式还是a.grad == c / a，这里的c / a为对应元素相除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)重新设计一个对控制流求梯度的例子。运行并分析结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1024.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g(a):\n",
    "    b = a * 4\n",
    "    while b.norm().asscalar() < 1000:\n",
    "        b = b * 4\n",
    "    if b.sum().asscalar() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c\n",
    "\n",
    "a = nd.random.normal(shape=1)\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c = g(a)\n",
    "c.backward()\n",
    "\n",
    "assert a.grad == c / a\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
