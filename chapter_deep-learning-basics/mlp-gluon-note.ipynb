{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 多层感知机的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们使用Gluon来实现上一节中的多层感知机。首先导入所需的包或模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.1 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和softmax回归唯一的不同在于，我们多加了一个全连接层作为隐藏层。它的隐藏单元个数为256，并使用ReLU函数作为激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'),\n",
    "       nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.2 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用与[“softmax回归的简洁实现”](softmax-regression-gluon.ipynb)一节中训练softmax回归几乎相同的步骤来读取数据并训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7943, train acc 0.700, test acc 0.829\n",
      "epoch 2, loss 0.4794, train acc 0.823, test acc 0.849\n",
      "epoch 3, loss 0.4250, train acc 0.843, test acc 0.833\n",
      "epoch 4, loss 0.3914, train acc 0.855, test acc 0.866\n",
      "epoch 5, loss 0.3740, train acc 0.862, test acc 0.869\n",
      "epoch 6, loss 0.3502, train acc 0.871, test acc 0.874\n",
      "epoch 7, loss 0.3388, train acc 0.874, test acc 0.877\n",
      "epoch 8, loss 0.3269, train acc 0.879, test acc 0.878\n",
      "epoch 9, loss 0.3140, train acc 0.885, test acc 0.881\n",
      "epoch 10, loss 0.3055, train acc 0.887, test acc 0.887\n",
      "epoch 11, loss 0.2961, train acc 0.891, test acc 0.879\n",
      "epoch 12, loss 0.2895, train acc 0.893, test acc 0.878\n",
      "epoch 13, loss 0.2783, train acc 0.898, test acc 0.881\n",
      "epoch 14, loss 0.2766, train acc 0.899, test acc 0.882\n",
      "epoch 15, loss 0.2704, train acc 0.900, test acc 0.890\n",
      "epoch 16, loss 0.2652, train acc 0.901, test acc 0.887\n",
      "epoch 17, loss 0.2576, train acc 0.904, test acc 0.890\n",
      "epoch 18, loss 0.2532, train acc 0.906, test acc 0.891\n",
      "epoch 19, loss 0.2479, train acc 0.907, test acc 0.887\n",
      "epoch 20, loss 0.2433, train acc 0.910, test acc 0.895\n",
      "epoch 21, loss 0.2422, train acc 0.909, test acc 0.892\n",
      "epoch 22, loss 0.2331, train acc 0.914, test acc 0.891\n",
      "epoch 23, loss 0.2289, train acc 0.914, test acc 0.890\n",
      "epoch 24, loss 0.2265, train acc 0.915, test acc 0.893\n",
      "epoch 25, loss 0.2268, train acc 0.916, test acc 0.894\n",
      "epoch 26, loss 0.2181, train acc 0.917, test acc 0.891\n",
      "epoch 27, loss 0.2159, train acc 0.919, test acc 0.894\n",
      "epoch 28, loss 0.2121, train acc 0.921, test acc 0.896\n",
      "epoch 29, loss 0.2068, train acc 0.923, test acc 0.899\n",
      "epoch 30, loss 0.2051, train acc 0.923, test acc 0.893\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 30\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "             None, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过Gluon可以更简洁地实现多层感知机。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 尝试多加入几个隐藏层，对比上一节中从零开始的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.3031, train acc 0.099, test acc 0.100\n",
      "epoch 2, loss 2.3030, train acc 0.102, test acc 0.100\n",
      "epoch 3, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 4, loss 2.3031, train acc 0.098, test acc 0.100\n",
      "epoch 5, loss 2.3032, train acc 0.098, test acc 0.100\n",
      "epoch 6, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 7, loss 2.3032, train acc 0.098, test acc 0.100\n",
      "epoch 8, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 9, loss 2.3031, train acc 0.099, test acc 0.100\n",
      "epoch 10, loss 2.3032, train acc 0.100, test acc 0.100\n",
      "epoch 11, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 12, loss 2.3030, train acc 0.100, test acc 0.100\n",
      "epoch 13, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 14, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 15, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 16, loss 2.3030, train acc 0.099, test acc 0.100\n",
      "epoch 17, loss 2.3032, train acc 0.099, test acc 0.100\n",
      "epoch 18, loss 2.3033, train acc 0.098, test acc 0.100\n",
      "epoch 19, loss 2.3030, train acc 0.102, test acc 0.100\n",
      "epoch 20, loss 2.3030, train acc 0.101, test acc 0.100\n",
      "epoch 21, loss 2.3031, train acc 0.099, test acc 0.100\n",
      "epoch 22, loss 2.3031, train acc 0.101, test acc 0.100\n",
      "epoch 23, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 24, loss 2.3031, train acc 0.099, test acc 0.100\n",
      "epoch 25, loss 2.3030, train acc 0.102, test acc 0.100\n",
      "epoch 26, loss 2.3031, train acc 0.098, test acc 0.100\n",
      "epoch 27, loss 2.3031, train acc 0.100, test acc 0.100\n",
      "epoch 28, loss 2.3031, train acc 0.098, test acc 0.100\n",
      "epoch 29, loss 2.3032, train acc 0.097, test acc 0.100\n",
      "epoch 30, loss 2.3031, train acc 0.097, test acc 0.100\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(256, activation='relu'),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "# 训练模型\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 30\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "             None, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用其他的激活函数，看看对结果的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.0487, train acc 0.609, test acc 0.759\n",
      "epoch 2, loss 0.5750, train acc 0.785, test acc 0.816\n",
      "epoch 3, loss 0.5037, train acc 0.816, test acc 0.827\n",
      "epoch 4, loss 0.4693, train acc 0.830, test acc 0.833\n",
      "epoch 5, loss 0.4483, train acc 0.838, test acc 0.845\n",
      "epoch 6, loss 0.4305, train acc 0.845, test acc 0.851\n",
      "epoch 7, loss 0.4141, train acc 0.850, test acc 0.854\n",
      "epoch 8, loss 0.4026, train acc 0.855, test acc 0.853\n",
      "epoch 9, loss 0.3933, train acc 0.858, test acc 0.857\n",
      "epoch 10, loss 0.3842, train acc 0.861, test acc 0.863\n",
      "epoch 11, loss 0.3789, train acc 0.863, test acc 0.862\n",
      "epoch 12, loss 0.3706, train acc 0.866, test acc 0.864\n",
      "epoch 13, loss 0.3628, train acc 0.870, test acc 0.869\n",
      "epoch 14, loss 0.3584, train acc 0.871, test acc 0.868\n",
      "epoch 15, loss 0.3536, train acc 0.873, test acc 0.874\n",
      "epoch 16, loss 0.3494, train acc 0.873, test acc 0.872\n",
      "epoch 17, loss 0.3451, train acc 0.875, test acc 0.872\n",
      "epoch 18, loss 0.3400, train acc 0.877, test acc 0.869\n",
      "epoch 19, loss 0.3367, train acc 0.878, test acc 0.868\n",
      "epoch 20, loss 0.3346, train acc 0.879, test acc 0.863\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='sigmoid'),\n",
    "       nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "# 训练模型\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "num_epochs = 20\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "             None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
